{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашняя работа часть 2  (5 баллов): совмещение спарсификации и квантизации.\n",
    "\n",
    "\n",
    "В этом задании вам предстоит совместить спарсификацию и квантизацию.\n",
    "\n",
    "Что бы упросить задание, мы не будем квантизовать всю модель, а квантизуем только по слоям.\n",
    "\n",
    "Резальтат работы это метрики L1 и L2  для $|C(W)X^T - WX^T|$ для каждого слоя, $С$  функция спарсификации и квантизации.\n",
    "\n",
    "\n",
    "В папке llama7b_weights содержатся веса для одоного слоя LLaMа7b и сопутствующие активации в папке llama7b_act_scales (аггрегировые по датасету)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4096, 11008])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load weights\n",
    "\n",
    "FOLDER = \"../llama7b_weights/\"\n",
    "names = os.listdir(FOLDER)\n",
    "weight_paths =  {name.replace(\".pt\",'') :os.path.join(FOLDER, name) for name in names}\n",
    "names = [name.replace(\".pt\",'') for name in names]\n",
    "W = torch.load(weight_paths[names[1]])\n",
    "W.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([11008, 11008])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Расчет матрицы гессе для слоя\n",
    "X = torch.load(\"../llama7b_act_scales/Llama-2-7b-hf.pt\")[names[1]]\n",
    "\n",
    "H = torch.outer(X, X)\n",
    "\n",
    "damp = 0.01 * torch.mean(torch.diag(H))\n",
    "diag = torch.arange(X.shape[0])\n",
    "H[diag, diag] += damp\n",
    "\n",
    "H = torch.linalg.cholesky(H)\n",
    "H = torch.cholesky_inverse(H)\n",
    "H = torch.linalg.cholesky(H, upper=True)\n",
    "Hinv = H\n",
    "H.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для вдохновения рекомендуем воспользоваться кодов QUIK\n",
    "\n",
    "https://github.com/IST-DASLab/QUIK/blob/9558d7121c698174fc93940e0b52c38c746c97ea/experiments/quik_utils.py#L80"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ваше решение тут ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Пример расчета ошибки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = W.float()\n",
    "X = X.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(158.4233)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Представим что l2 наша функция квантизации\n",
    "\n",
    "l2 = ((W@X.T - torch.round(W)@X.T)**2).mean()\n",
    "l2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
